#ifdef SOON
/*
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXX
XXX  EVERYTHING BELOW HERE IS OLD STUFF KEPT FOR REFERENCE DURING IMPLEMENTATION -- DELETEME DELETEME DELETEME
XXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
*/

// #define ARENA_FNAME  tmpnam(0)
#define ARENA_FNAME  "/tmp/sml-mp.mutex-arena"

#define INT_LIB7inc(n,i)  ((Val)TAGGED_INT_FROM_C_INT(TAGGED_INT_TO_C_INT(n) + (i)))
#define INT_LIB7dec(n,i)  (INT_LIB7inc(n,(-i)))
//
static Mutex      AllocLock ();        
static Barrier*  AllocBarrier();
//
static usptr_t*	arena;								// Arena for shared sync chunks.
//
static ulock_t	MP_ArenaLock;							// Must be held to alloc/free a mutex.
//
static ulock_t	MP_ProcLock;							// Must be held to acquire/release procs.




//
void   pth__shut_down   ()   {
    // ==============
    //
    usdetach( arena );												// 'usdetach' appears nowhere else in codebase; must be the SGI equivalent to posix 'munmap'
}

//
Pid   pth__pthread_id   ()   {
    //===============
    //
    // Called only from:    src/c/main/runtime-state.c
    //
    return getpid ();
}

//
static Mutex   allocate_mutex   ()   {
    //         ==============
    //
    // Allocate and initialize a system mutex.

    ulock_t	mutex;

    if ((mutex = usnewlock(arena)) == NULL)   die ("allocate_mutex: cannot get mutex with usnewlock\n");

    usinitlock(mutex);
    usunsetlock(mutex);

    return mutex;


}
 
//
void   pth__mutex_lock   (Mutex mutex)   {
    // ===============
    //
    ussetlock(mutex);
}

//
void   pth__mutex_unlock   (Mutex mutex)   {
    // =================
    //
    usunsetlock(mutex);
}

//
Bool   pth__mutex_maybe_lock   (Mutex mutex)   {
    // =====================
    //
    return ((Bool) uscsetlock(mutex, 1));		// Try once.
}

//
Mutex   pth__make_mutex   ()   {
    //  ===============
    //
    ulock_t mutex;

    ussetlock(   MP_ArenaLock );
        //
	mutex = allocate_mutex ();
        //
    usunsetlock( MP_ArenaLock );

    return mutex;
}


//
void   pth__free_mutex   (Mutex mutex)   {
    // ===============
    //
    ussetlock(MP_ArenaLock);
        usfreelock(mutex,arena);
    usunsetlock(MP_ArenaLock);
}

//
static Barrier*   allocate_barrier   ()   {
     //           ================
     //
     // Allocate and initialize a system barrier.

    barrier_t *barrierp;

    if ((barrierp = new_barrier(arena)) == NULL)   die ("Cannot get barrier with new_barrier");

    init_barrier(barrierp);

    return barrierp;
}
  

//
Barrier*   pth__make_barrier   ()   {
    //     =================
    //
    barrier_t *barrierp;

    ussetlock(    MP_ArenaLock );
        //
	barrierp = allocate_barrier ();
        //
    usunsetlock( MP_ArenaLock );

    return barrierp;
}


//
void   pth__free_barrier   (Barrier* barrierp)   {
    // =================
    //
    ussetlock(MP_ArenaLock);
	//
	free_barrier( ebarrierp );
	//
    usunsetlock(MP_ArenaLock);
}


//
void   pth__wait_at_barrier   (Barrier* barrierp,  unsigned n)   {
    // ====================
    //
    barrier( barrierp, n );
}


//
static void   fix_pnum   (int n)   {
    //        ========
    //
    // Dummy for now.
}
 

//
static void   pthread_main   (void* vtask)   {
    //        ============
    //
    Task* task = (Task*) vtask;

// Needs to be done  	XXX BUGGO FIXME
//    fix_pnum(task->pnum);
//    setup_signals(task, TRUE);
//

    // Spin until we get our id (from return of call to sproc_wrapper)
    //
    while (task->pthread->pid == NULL) {
	//
	#ifdef NEED_PTHREAD_SUPPORT_DEBUG
	    debug_say("[waiting for self]\n");
	#endif
	continue;
    }
    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say ("[new proc main: releasing mutex]\n");
    #endif

    pth__mutex_unlock( MP_ProcLock );			// Implicitly handed to us by the parent.
    run_mythryl_task_and_runtime_eventloop( task );				// run_mythryl_task_and_runtime_eventloop		def in   src/c/main/run-mythryl-code-and-runtime-eventloop.c
    //
    // run_mythryl_task_and_runtime_eventloop should never return:
    //
    die ("pthread returned after run_mythryl_task_and_runtime_eventloop() in pthread_main().\n");
}


//
static int   sproc_wrapper   (Task* state)   {
    //       ============
    //
    int error;

    int result = sproc(pthread_main, PR_SALL, (void *)state);

    if (result == -1) {
	extern int errno;

	error = oserror();	// This is potentially a problem since
				// each thread should have its own errno.
				// see sgi man pages for sproc.			XXX BUGGO FIXME

	say_error( "error=%d,errno=%d\n", error, errno );
	say_error( "[warning sproc_wrapper: %s]\n",strerror(error) );
    } 

    return result;
}

									// typedef   struct task   Task;	def in   src/c/h/runtime-base.h
									// struct task				def in   src/c/h/task.h
Val   pth__pthread_create   (Task* task, Val current_thread, Val closure_arg)   {
    //===================
    //
    // This fn is called (only) by   spawn_pthread ()   in   src/c/lib/pthread/libmythryl-pthread.c
    //
    pth__done_pthread_create__global = TRUE;

    Task*    task;
    Pthread* pthread;

    int i;

    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say("[acquiring proc]\n");
    #endif

    pth__mutex_lock( MP_ProcLock );

    // Search for a suspended kernel thread to reuse:
    //
    for (i = 0;
	(i < MAX_PTHREADS)  &&  (pthread_table__global[i]->status != PTHREAD_IS_SUSPENDED);
	i++
    ) {
	continue;
    }
    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say("[checking for suspended processor]\n");
    #endif

    if (i == MAX_PTHREADS) {
        //
	if (DEREF( ACTIVE_PTHREADS_COUNT_REFCELL__GLOBAL ) == TAGGED_INT_FROM_C_INT( MAX_PTHREADS )) {
	    //
	    pth__mutex_unlock( MP_ProcLock );
	    say_error("[processors maxed]\n");
	    return HEAP_FALSE;
	}
	#ifdef NEED_PTHREAD_SUPPORT_DEBUG
	    debug_say("[checking for NO_PROC]\n");
	#endif

	// Search for a slot in which to put a new pthread
	//
	for (i = 0;
	    (i < MAX_PTHREADS)  &&  (pthread_table__global[i]->status != NO_PTHREAD_ALLOCATED);
	    i++
	){
	    continue;
	}

	if (i == MAX_PTHREADS) {
	    //
	    pth__mutex_unlock( MP_ProcLock );
	    say_error("[no processor to allocate]\n");
	    return HEAP_FALSE;
	}
    }
    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say("[using processor at index %d]\n", i);
    #endif

    // Use pthread at index i:
    //
    pthread =  pthread_table__global[ i ];

    task =  pthread->task;

    task->exception_fate	=  PTR_CAST( Val,  handle_v + 1 );
    task->argument		=  HEAP_VOID;
    //
    task->fate			=  PTR_CAST( Val, return_c);
    task->current_closure	=  closure_arg;
    //
    task->program_counter	= 
    task->link_register		=  GET_CODE_ADDRESS_FROM_CLOSURE( closure_arg );
    //
    task->current_thread	=  current_thread;
  
    if (pthread->status == NO_PTHREAD_ALLOCATED) {
	//
        // Assume we get one:

	ASSIGN( ACTIVE_PTHREADS_COUNT_REFCELL__GLOBAL, INT_LIB7inc( DEREF(ACTIVE_PTHREADS_COUNT_REFCELL__GLOBAL), 1) );

	if ((pthread->pid = sproc_wrapper(p)) != -1) {
	    //
	    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
		debug_say ("[got a processor]\n");
	    #endif

	    pthread->status = PTHREAD_IS_RUNNING;

	    // pthread_main will release MP_ProcLock.

	    return HEAP_TRUE;

	} else {

	    ASSIGN( ACTIVE_PTHREADS_COUNT_REFCELL__GLOBAL, INT_LIB7dec(DEREF(ACTIVE_PTHREADS_COUNT_REFCELL__GLOBAL), 1) );
	    pth__mutex_unlock(MP_ProcLock);
	    return HEAP_FALSE;
	}      

    } else {

	pthread->status = PTHREAD_IS_RUNNING;

	#ifdef NEED_PTHREAD_SUPPORT_DEBUG
	    debug_say ("[reusing a processor]\n");
	#endif

	pth__mutex_unlock(MP_ProcLock);

	return HEAP_TRUE;
    }
}						// fun pth__pthread_create


//
void   pth__pthread_exit   (Task* task)   {
    // ====================
    //
    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say("[release_pthread: suspending]\n");
    #endif

    call_heapcleaner( task, 1 );							// call_heapcleaner		def in   /src/c/heapcleaner/call-heapcleaner.c

    pth__mutex_lock(MP_ProcLock);

    task->pthread->status = PTHREAD_IS_SUSPENDED;

    pth__mutex_unlock(MP_ProcLock);

    while (task->pthread->status == PTHREAD_IS_SUSPENDED) {
	//
	call_heapcleaner( task, 1 );										// Need to be continually available for garbage collection.
    }
    #ifdef NEED_PTHREAD_SUPPORT_DEBUG
	debug_say("[release_pthread: resuming]\n");
    #endif

    run_mythryl_task_and_runtime_eventloop( task );								// run_mythryl_task_and_runtime_eventloop		def in   src/c/main/run-mythryl-code-and-runtime-eventloop.c

    die ("return after run_mythryl_task_and_runtime_eventloop(task) in mp_release_pthread\n");
}






#endif

